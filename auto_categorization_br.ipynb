{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301477eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "from unidecode import unidecode\n",
    "from IPython.display import display, HTML  \n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\")) # widht jupyter notebook\n",
    "pd.set_option('display.max_colwidth', None) # width dataframe as output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59dc4a00",
   "metadata": {},
   "source": [
    "# 0- Fetch and clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c624cf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up File names\n",
    "\n",
    "\n",
    "data_niq_path = r'data/pm_result_cosmetics.csv' #'breadcrumb_fr', product_name\n",
    "regex_model_path = r'data/regex_model_cosmetics_full.csv' \n",
    "\n",
    "data_extract_path = r'data/training_dataset_cosmetics.csv' # 'product_concat','breadcrumb_aggregate'\n",
    "#df_volume_checks_path = r'data/volume_checks_cosmetics_full.csv'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "perc_max_prod_catch_from_other_bc = 0.01 #0.05 #check the perc of products catch from other bc. If higher than x% then pop.\n",
    "regex_count_threshold = 10 # >= 2\n",
    "\n",
    "\n",
    "\n",
    "#### list breadcrumbs inside our Fox Categ - in French and with 4 levels ####\n",
    "\n",
    "category_breadcrumb = [\n",
    "\"beaute et parfum_maquillage_yeux_kits\",\n",
    "\"beaute et parfum_maquillage_teint_kits\",\n",
    "\"beaute et parfum_maquillage_levres_kits\",\n",
    "\"beaute et parfum_maquillage_teint_blush\",\n",
    "\"beaute et parfum_maquillage_levres_gloss\",\n",
    "\"beaute et parfum_maquillage_yeux_mascara\",\n",
    "\"beaute et parfum_maquillage_corps_bronzer\",\n",
    "\"beaute et parfum_maquillage_teint_bronzer\",\n",
    "\"beaute et parfum_maquillage_yeux_sourcils\",\n",
    "\"beaute et parfum_maquillage_yeux_eye-liner\",\n",
    "\"beaute et parfum_maquillage_yeux_faux cils\",\n",
    "\"beaute et parfum_maquillage_teint_correcteurs\",\n",
    "\"beaute et parfum_maquillage_corps_illuminateur\",\n",
    "\"beaute et parfum_maquillage_levres_crayon a levre\",\n",
    "\"beaute et parfum_maquillage_levres_rouge a levres\",\n",
    "\"beaute et parfum_maquillage_yeux_fard a paupieres\",\n",
    "\"beaute et parfum_maquillage_coffrets de maquillage\",\n",
    "\"beaute et parfum_maquillage_palettes de maquillage\",\n",
    "\"beaute et parfum_maquillage_teint_poudre de visage\",\n",
    "\"beaute et parfum_maquillage_corps_poudre de finition\",\n",
    "\"beaute et parfum_maquillage_corps_decoration de la peau\",\n",
    "\"beaute et parfum_maquillage_levres_volumateur de levres\",\n",
    "\"beaute et parfum_maquillage_teint_fond de teint et base\",\n",
    "\"beaute et parfum_maquillage_corps_fond de teint - poudre\",\n",
    "\"beaute et parfum_maquillage_corps_fond de teint - liquide\",\n",
    "\"beaute et parfum_accessoires et outils_accessoires de maquillage et outils\",\n",
    "\"beaute et parfum_vernis a ongles et manucure_soins pour les ongles\",\n",
    "\"beaute et parfum_vernis a ongles et manucure_decorations et accessoires\",\n",
    "\"beaute et parfum_vernis a ongles et manucure_faux ongles et accessoires\",\n",
    "\"beaute et parfum_vernis a ongles et manucure_kits de soins pour les ongles\",\n",
    "\"beaute et parfum_vernis a ongles et manucure_decorations et accessoires_dissolvant\",\n",
    "\"beaute et parfum_vernis a ongles et manucure_faux ongles et accessoires_faux ongles\",\n",
    "\"beaute et parfum_vernis a ongles et manucure_decorations et accessoires_vernis a ongles\",\n",
    "\"beaute et parfum_vernis a ongles et manucure_decorations et accessoires_blanchisseur d'ongles\",\n",
    "\"beaute et parfum_vernis a ongles et manucure_machines electriques pour manucures et pedicures\",\n",
    "\"beaute et parfum_vernis a ongles et manucure_decorations et accessoires_decorations et accessoires\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45050d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add _uncategorized until level 3 for df_bc_regex\n",
    "def add_uncategorized(bc):\n",
    "    if len(re.findall(\"_\", bc)) == 3 :\n",
    "        return(bc)\n",
    "    elif len(re.findall(\"_\", bc)) == 2 :\n",
    "        return(bc + \"_uncategorized\")\n",
    "    elif len(re.findall(\"_\", bc)) == 1 :\n",
    "        return(bc + \"_uncategorized_uncategorized\")\n",
    "    elif len(re.findall(\"_\", bc)) == 0 :\n",
    "        return(bc + \"_uncategorized_uncategorized_uncategorized\")\n",
    "    else :\n",
    "        return(bc)\n",
    "\n",
    "##### ONLY APPLIES WHEN SPLITTING BC IN OUT SCOPE IN REGEX MODEL GENERATION ######\n",
    "# update breadcrumbs for in scope = keep full breadcrumb ; out scope = categ0_uncat_uncat_uncat\n",
    "def split_bc_in_out_scope(bc, category_breadcrumb=category_breadcrumb):\n",
    "    category_0_scope =[]\n",
    "    for breadcrumb in category_breadcrumb : \n",
    "        category_0_scope.append(breadcrumb.split(\"_\")[0])\n",
    "    \n",
    "    if bc.split(\"_\")[0] not in category_0_scope :\n",
    "        return(f'{bc.split(\"_\")[0]}_uncategorized_uncategorized_uncategorized')\n",
    "    else :\n",
    "        return(bc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5150bc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data_niq sent by NIQ with product_name and modules/breadcrumb \n",
    "data_niq = pd.read_csv(data_niq_path)\n",
    "data_niq = data_niq.rename(columns= {'breadcrumb_fr':'breadcrumb'})\n",
    "data_niq = data_niq.drop_duplicates()\n",
    "data_niq = data_niq.dropna() # removing empty product_name\n",
    "\n",
    "#data_niq['product_name'].replace('', np.nan, inplace=True)   \n",
    "data_niq.dropna(subset=['product_name'], inplace=True)\n",
    "data_niq = data_niq.apply(lambda x: x.astype(str).str.lower())    # and double check that all chars are lowercase\n",
    "data_niq['breadcrumb'] = data_niq['breadcrumb'].apply(add_uncategorized)\n",
    "##### ONLY APPLIES WHEN SPLITTING BC IN OUT SCOPE IN REGEX MODEL GENERATION ######\n",
    "data_niq['breadcrumb'] = data_niq['breadcrumb'].apply(split_bc_in_out_scope)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88865bb6",
   "metadata": {},
   "source": [
    "# 1- Build the regex model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752e25d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to clean product_name\n",
    "def product_cleaner(product_name):\n",
    "    product_name_clean = product_name.lower() #lower case\n",
    "    product_name_clean = unidecode(product_name_clean) # convert all chars to ascii (é -> e , ù -> u)\n",
    "    \n",
    "    ########### short way with .*\n",
    "    product_name_clean = re.sub(r\"_|[^\\w\\s]+\", r\" \", product_name_clean) # remove special chars \n",
    "    product_name_clean = re.sub(r\"\\d\", r\" \", product_name_clean)  # remove digits\n",
    "    product_name_clean = re.sub(r\"\\b.\\b\", r\" \", product_name_clean) # remove unique char\n",
    "    \n",
    "    # Remove Stopwords\n",
    "    # Global\n",
    "    product_name_clean = re.sub(r\"\\b(cm|kg|cl|ml)\\b\", r\" \", product_name_clean) \n",
    "    # EN\n",
    "    product_name_clean = re.sub(r\"\\b(and|for|with|per|or|to|by|not|in|all|the)\\b\", r\" \", product_name_clean) \n",
    "    # FR\n",
    "    product_name_clean = re.sub(r\"\\b(par|de|sous|ou|et|en|la|le|au)\\b\", r\" \", product_name_clean) \n",
    "    # DE\n",
    "    product_name_clean = re.sub(r\"\\b(und|mit|der|das|die)\\b\", r\" \", product_name_clean) \n",
    "    # ES & IT\n",
    "    product_name_clean = re.sub(r\"\\b(sin|con|di|da|el|del|para|por|el)\\b\", r\" \", product_name_clean) \n",
    "\n",
    "    \n",
    "    ########### short way\n",
    "    \n",
    "    \n",
    "    ########### long way\n",
    "    #product_name_clean = re.sub(r\"_|[^\\w\\s]+\", r\".?\", product_name_clean) # special chars to single space .?  we can't replace special chars by spaces as later we can combine 2 words next to each others\n",
    "    #product_name_clean = re.sub(r\"\\d+\", r\"\\\\d+\", product_name_clean)  # number(s) to \\d+\n",
    "    #product_name_clean = re.sub(r\"\\sand\\s\", r\" (and\\\\s)?\", product_name_clean)  \n",
    "    #product_name_clean = re.sub(r\"\\sund\\s\", r\" (und\\\\s)?\", product_name_clean)  \n",
    "    #product_name_clean = re.sub(r\"\\set\\s\", r\" (et\\\\s)?\", product_name_clean) \n",
    "    #product_name_clean = re.sub(r\"\\si\\s\", r\" (i\\\\s)?\", product_name_clean) \n",
    "    ########### long way\n",
    "\n",
    "    product_name_clean = re.sub(r\"\\s+\", r\" \", product_name_clean)  # space(s) to single space [ ]\n",
    "    #product_name_clean = re.sub(r\"(y|ies)(\\b)\", r\"(y|ie?s?) \", product_name_clean)  # for english words : plural \"ies\" and singular \"y\" to \"(y|ie?s?)\"\"\n",
    "    #product_name_clean = re.sub(r\"s(\\b)\", r\"s? \", product_name_clean)  # plural \"s\" to \"s?\"\n",
    "\n",
    "    return product_name_clean\n",
    "\n",
    "########################################################\n",
    "#product_name = \"hello Alex and Tom 12 ml and,,,,, +334 at $1 + yolo   in-the_place!!!!candies and french fries \\\\ / |in the %&pastes\"\n",
    "product_name = \"hello,,,,, yos l de \"\n",
    "product_clean = product_cleaner(product_name)\n",
    "print(product_clean)\n",
    "########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0727103",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to extract all possible regex by product_name\n",
    "def regex_constructor(product_name):\n",
    "    word_list = product_name.split()\n",
    "    regex_list = []\n",
    "\n",
    "    if len(word_list) > 0 : \n",
    "        # word\\sword -> \"how are you\" to [how, how\\sare, how\\sare\\syou, are, are\\syou, you]\n",
    "        index = 0\n",
    "        for word in word_list :\n",
    "            index += 1\n",
    "            for check_index in range(index,len(word_list)+1) : \n",
    "                new_regex = [word] + word_list[index:check_index]\n",
    "                new_regex = '\\\\s'.join(new_regex)\n",
    "                regex_list.append(new_regex)\n",
    "\n",
    "        # word.*word -> \"how are you\" to [how.*are, how.*you, are.*you]\n",
    "        index = 0\n",
    "        for word in word_list :\n",
    "            index += 1\n",
    "            for check_index in range(index+1,len(word_list)+1) : \n",
    "                new_regex = word + \".*\" + word_list[check_index-1]\n",
    "                regex_list.append(new_regex)\n",
    "\n",
    "        # ^word\\sword -> \"how are you\" to [^how, ^how.*are, ^how.*you]\n",
    "        index = 1\n",
    "        for check_index in range(index,len(word_list)) : \n",
    "            first_word = \"^\" + word_list[0]\n",
    "            other_word = word_list[check_index]\n",
    "            new_regex = [first_word] + [other_word]\n",
    "            new_regex = '.*'.join(new_regex)\n",
    "            regex_list.append(new_regex)\n",
    "\n",
    "        # word.*word\\sword -> \"how are you guys\" to [how.*are\\syou, how.*you\\sguys, are.*you\\sguys]\n",
    "        #index = 0\n",
    "        #for word in word_list :\n",
    "        #    index += 1\n",
    "        #    for check_index in range(index+1,len(word_list)) : \n",
    "        #        new_regex = word + \".*\" + word_list[check_index-1] + \"\\s\" + word_list[check_index]\n",
    "        #        regex_list.append(new_regex)\n",
    "\n",
    "\n",
    "        # word\\sword.*word -> \"how are you guys\" to [how\\\\sare.*you, how\\\\sare.*guys, are\\\\syou.*guys]\n",
    "        #for index in range(0,len(word_list)-2) :\n",
    "        #    for check_index in range(index+2,len(word_list)):   \n",
    "        #        new_regex = word_list[index] + \"\\\\s\" + word_list[index+1] + \".*\" + word_list[check_index]\n",
    "        #        regex_list.append(new_regex)\n",
    "\n",
    "\n",
    "        # ^word\\sword -> \"how are you\" to [^how, ^how\\sare, ^how\\sare\\syou]\n",
    "        #index = 1\n",
    "        #first_word = \"^\" + word_list[0]\n",
    "        #for check_index in range(index,len(word_list)+1) : \n",
    "        #    new_regex = [first_word] + word_list[index:check_index]\n",
    "        #    new_regex = '\\\\s'.join(new_regex)\n",
    "        #    regex_list.append(new_regex)\n",
    "        \n",
    "            \n",
    "        # ^word\\sword -> \"how are you\" to [^how, ^how.*are, ^how.*are.*you]\n",
    "        #index = 1\n",
    "        #first_word = \"^\" + word_list[0]\n",
    "        #for check_index in range(index,len(word_list)+1) : \n",
    "        #    new_regex = [first_word] + word_list[index:check_index]\n",
    "        #    new_regex = '.*'.join(new_regex)\n",
    "        #    regex_list.append(new_regex)\n",
    "\n",
    "        regex_list = list(set(regex_list)) #remove duplicates from the regex list (for example in case of 2 similar words in the produc_name)\n",
    "        return regex_list\n",
    "\n",
    "########################################################\n",
    "regex_list = regex_constructor(product_clean)\n",
    "regex_list\n",
    "########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a0ac17",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "%%time\n",
    "# EXTRACT {bc1 : [(regex1,10), (regex2, 5)], bc10 : [(regex11,10), (regex12, 5)]} from NIQ files \n",
    "regex_count_threshold = regex_count_threshold # >= 2\n",
    "\n",
    "\n",
    "df = data_niq.copy()\n",
    "\n",
    "# create a list of all regex possibilities per bc\n",
    "bc_regex = {k: [] for k in df['breadcrumb'].unique()}\n",
    "for index, row in tqdm(df.iterrows(), desc='Regex List Creation'):\n",
    "    bc = row['breadcrumb']\n",
    "    product_name = product_cleaner(row['product_name'])  # clean the product_name\n",
    "    regex_list = regex_constructor(product_name)         # build the list of possible regex for current product_name\n",
    "    if regex_list is not None :\n",
    "        bc_regex[bc].append(regex_list)\n",
    "\n",
    "# from a list with all possible regex, change to a list of distinct regex with count, and remove regex with lower count than regex_count_threshold\n",
    "bc_regex_count = {k: [] for k in df['breadcrumb'].unique()}\n",
    "for bc, regex in tqdm(bc_regex.items(), desc='Regex List Count Creation') :\n",
    "    regex_list = sum(regex, []) # replace mutliple list of values into one list {bc : [[regex1, regex2][regex3,regex4]]} to {bc : [regex1, regex2, regex3,regex4]}\n",
    "    regex_count = Counter(regex_list)   # count how many distinct regex per bc\n",
    "    regex_count = sorted(regex_count.items(), key=lambda x:x[1], reverse=True) #sort in descending order the values\n",
    "    regex_count_with_threshold = []\n",
    "\n",
    "    for rx in regex_count :     # remove all regex_count with minimum of n \n",
    "        if rx[1] >= regex_count_threshold:\n",
    "            regex_count_with_threshold.append(rx)\n",
    "  \n",
    "    bc_regex_count[bc] = regex_count_with_threshold\n",
    "\n",
    "# check if regex doesn't match product_names from other bc, and output a dict with key= bc and value= list of valid regex\n",
    "data_bc_regex_valid = []\n",
    "bc_regex_valid = {}\n",
    "for bc, regex_list in tqdm(bc_regex_count.items(), desc='Check if no match other BC'):\n",
    "    regex_valid = dict(regex_list)                # we convert from list of list of tuples to dictionary of key : value because of the pop function to use later\n",
    "    df_diff_bc = df.loc[df['breadcrumb'] != bc]   # build df with different bc\n",
    "\n",
    "    for regex in tqdm(list(regex_valid), desc=f'--Loop over regex_valid for {bc}'): # we convert regex_valid to list because the length is moving when iterating the loop\n",
    "        try :\n",
    "            r = re.compile(f'.*{regex}.*')\n",
    "            r_list = list(filter(r.match, list(df_diff_bc['product_name'])))    # we use this regex construction to catch all matches inside a list, rather than just one string\n",
    "            # previous method. very restrictiv\n",
    "            #if len(r_list) > 0: # if we catch at least one string, then remove the regex from the regex_valid list\n",
    "            # new method less restrictive\n",
    "            #check the perc of products catch from other bc. If higher than x% then pop.\n",
    "            if len(r_list) / regex_valid[regex] > perc_max_prod_catch_from_other_bc : # number of product catch in other bc / number of products catch in the bc.\n",
    "                regex_valid.pop(regex)\n",
    "\n",
    "        except re.error:    # if one regex is problematci (for example *) then remove from regex_valid list\n",
    "            regex_valid.pop(regex) \n",
    "            #print(f'{regex[0]} not valid')\n",
    "            continue\n",
    "\n",
    "\n",
    "    regex_valid_list = [(k, v) for k, v in regex_valid.items()] # convert list of dict to list of list of tuples \n",
    "    data_bc_regex_valid.append({'breadcrumb': bc, 'regex_list':regex_valid_list})\n",
    "\n",
    "    df_clean = pd.DataFrame.from_dict(data_bc_regex_valid)\n",
    "    df_clean.to_csv(regex_model_path)\n",
    "\n",
    "df_clean\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7722cf29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983e2174",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ad9338",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fcfcf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29f7c1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fceae8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efeed64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921e0d0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbe13c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5afe39b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c4b1d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1edb2da5",
   "metadata": {},
   "source": [
    "# 2- Generate the BR with Categ Extract and Regex Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ae2db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################################\n",
    "\n",
    "bc_origin = \"beaute et parfum_maquillage_coffrets de maquillage_uncategorized\"\n",
    "bc_dest = \"beaute et parfum_maquillage_yeux_mascara\"\n",
    "\n",
    "\n",
    "############################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94119ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the data\n",
    "\n",
    "data_bc_regex = pd.read_csv(regex_model_path)\n",
    "data_bc_regex['breadcrumb'] = data_bc_regex['breadcrumb'].apply(add_uncategorized)\n",
    "\n",
    "data_extract = pd.read_csv(data_extract_path)\n",
    "data_extract = data_extract[['product_concat', 'breadcrumb_aggregate']]\n",
    "data_extract = data_extract.dropna()\n",
    "data_extract = data_extract.rename(columns= {'product_concat':'product_name','breadcrumb_aggregate':'breadcrumb'})\n",
    "data_extract['breadcrumb'] = data_extract['breadcrumb'].apply(add_uncategorized)\n",
    "data_extract = data_extract.apply(lambda x: x.astype(str).str.lower())    # all chars to lowercase\n",
    "data_extract.drop_duplicates(subset=\"product_name\",keep=False, inplace=True)\n",
    "#data_extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f50af76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BC ORIGIN (pred_breadcrumb)\n",
    "df_extract = data_extract[data_extract['breadcrumb'] == bc_origin]\n",
    "df_extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd984e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BC DESTINATION (real_breadcrumb)\n",
    "target_values = [bc_origin, bc_dest]\n",
    "df_bc_regex = data_bc_regex[data_bc_regex['breadcrumb'].isin(target_values)]  \n",
    "df_bc_regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99186791",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# build df with all regex_valid per product : product_name | bc_origin | {bc_dest : [(regex, count), (regex, count)] , bc_dest : [] }\n",
    "df_product_regex_valid = df_extract.copy()\n",
    "\n",
    "\n",
    "# buid a df with 1 column per bc_dest and empty list\n",
    "df_result = df_product_regex_valid.copy()\n",
    "#bc_dest_list = [k for k in df_bc_regex['breadcrumb'].unique()]\n",
    "#for bc_dest in bc_dest_list :\n",
    "#    df_result[bc_dest] = np.empty((len(df_result), 0)).tolist()\n",
    "    \n",
    "bc_dest_list = {k : np.empty((len(df_result), 0)).tolist() for k in df_bc_regex['breadcrumb'].unique()}\n",
    "new_columns = pd.DataFrame(bc_dest_list)\n",
    "df_result = pd.concat([df_result.reset_index(drop=True), new_columns.reset_index(drop=True)], axis=1)\n",
    "\n",
    "\n",
    "# loop over the dict bc : regex valid list\n",
    "for index, row in tqdm(df_bc_regex.iterrows()):\n",
    "    # check if there are a regex inside the regex list\n",
    "    if len(row['regex_list']) > 0 :\n",
    "        # convert the regex_list as actual list\n",
    "        regex_list = eval(row['regex_list'])\n",
    "        for regex in regex_list :\n",
    "            r = re.compile(f'.*{regex[0]}.*')\n",
    "            # we build a list of products that match the regex\n",
    "            match_list = list(filter(r.match, list(df_extract['product_name'])))\n",
    "            if len(match_list) > 0 :\n",
    "                for match in match_list :\n",
    "                    # add the regex to the regex list for the right bc and for a specific product name (match)\n",
    "                    m = df_result['product_name'].eq(match)\n",
    "                    df_result[row['breadcrumb']] = df_result[row['breadcrumb']].mask(m, df_result[row['breadcrumb']].apply(lambda x: x + [regex]))\n",
    "\n",
    "\n",
    "df_result.set_index(\"product_name\", inplace=True)\n",
    "# remove column bc_origin\n",
    "df_only_bc_dest = df_result.drop(df_result.columns[[0]], axis=1)\n",
    "dict_index_bc_regex = df_only_bc_dest.to_dict(orient=\"index\")\n",
    "\n",
    "# we add the dict bc_dest : list of valid regex to the df with product name and bc_origin\n",
    "for k,v in dict_index_bc_regex.items() : \n",
    "    df_product_regex_valid.loc[df_product_regex_valid['product_name'] ==k, 'bc_regex_valid'] = [v]\n",
    "\n",
    "df_product_regex_valid = df_product_regex_valid.rename(columns= {'breadcrumb':'bc_origin'})\n",
    "df_product_regex_valid.to_csv('data/df_product_regex_valid.csv')\n",
    "df_product_regex_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d042e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check number of bc_regex per product and populate product not catch , product catch with several bc , product catch with unique bc \n",
    "df_product_not_catch = pd.DataFrame(columns=['product_name', 'bc_origin', 'bc_regex_valid'])\n",
    "df_product_catch_sent_several_bc = pd.DataFrame(columns=['product_name', 'bc_origin', 'bc_regex_valid'])\n",
    "\n",
    "df_product_catch_sent_unique_bc = pd.DataFrame(columns=['product_name', 'bc_origin', 'bc_regex_valid'])\n",
    "df_bc_regex_final = pd.DataFrame(columns=['product_name', 'bc_origin', 'bc_regex_valid'])\n",
    "\n",
    "for index, row_valid in tqdm(df_product_regex_valid.iterrows()):\n",
    "    bc_regex_valid = {}\n",
    "    for breadcrumb, regex_list in row_valid['bc_regex_valid'].items():\n",
    "        if regex_list : \n",
    "            bc_regex_valid[breadcrumb] = regex_list\n",
    "\n",
    "    if len(bc_regex_valid) == 0 : # if no valid regex then send to df_product_not_catch\n",
    "        df_product_not_catch_newrow = pd.DataFrame({'product_name': [row_valid['product_name']], 'bc_origin': [row_valid['bc_origin']], 'bc_regex_valid': [np.nan]})\n",
    "        df_product_not_catch = pd.concat([df_product_not_catch, df_product_not_catch_newrow], axis=0)\n",
    "\n",
    "    elif len(bc_regex_valid) == 1 : # if only 1 regex valid then send to df_product_catch_sent_unique_bc\n",
    "        df_product_catch_sent_unique_bc_newrow = pd.DataFrame({'product_name': [row_valid['product_name']], 'bc_origin': [row_valid['bc_origin']], 'bc_regex_valid': [bc_regex_valid]})\n",
    "        df_product_catch_sent_unique_bc = pd.concat([df_product_catch_sent_unique_bc, df_product_catch_sent_unique_bc_newrow], axis=0, ignore_index=True)\n",
    "    elif len(bc_regex_valid) > 1 : # if more than 1 regex valid then send to df_product_catch_sent_several_bc\n",
    "        df_product_catch_sent_several_bc_newrow = pd.DataFrame({'product_name': [row_valid['product_name']], 'bc_origin': [row_valid['bc_origin']], 'bc_regex_valid': [bc_regex_valid]})\n",
    "        df_product_catch_sent_several_bc = pd.concat([df_product_catch_sent_several_bc, df_product_catch_sent_several_bc_newrow], axis=0, ignore_index=True)\n",
    "\n",
    "df_product_catch_sent_unique_bc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6956ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "### FILTER ON BC ORIGIN ###\n",
    "# Clean df_product_catch_sent_unique_bc to keep only products covered by the BR :\n",
    "df_product_in_scope = pd.DataFrame(columns=['product_name', 'bc_origin', 'bc_regex_valid'])\n",
    "for index, row in tqdm(df_product_catch_sent_unique_bc.iterrows()):\n",
    "\n",
    "    df_product_in_scope_newrow = pd.DataFrame({'product_name': [row['product_name']], 'bc_origin':[row['bc_origin']], 'bc_regex_valid':[row['bc_regex_valid']]})\n",
    "    # if bc_origin in scope then keep product # Precision\n",
    "    if row['bc_origin'] in category_breadcrumb :\n",
    "        df_product_in_scope = pd.concat([df_product_in_scope, df_product_in_scope_newrow], axis=0, ignore_index=True)\n",
    "    # if bc_origin out scope & bc_dest in scope then keep product # Recall\n",
    "    elif row['bc_origin'] not in category_breadcrumb and list(row['bc_regex_valid'].keys())[0] in category_breadcrumb :\n",
    "        df_product_in_scope = pd.concat([df_product_in_scope, df_product_in_scope_newrow], axis=0, ignore_index=True)\n",
    "    # if bc_origin out scope & bc_dest out scope then throw away product\n",
    "    else : \n",
    "        continue\n",
    "df_product_in_scope\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b8332f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### RE-FORMAT DF###\n",
    "# Re-format a new df from df_product_in_scope with product_name , bc_dest and regex_valid_list\n",
    "df_product_bc_regex = df_product_in_scope.copy()\n",
    "df_product_bc_regex.insert(1,'bc_dest', np.nan)     #insert the bc_dest column\n",
    "df_product_bc_regex.insert(2,'regex_valid_list', np.nan)     #insert the bc_dest column\n",
    "\n",
    "for index, row in tqdm(df_product_bc_regex.iterrows()):\n",
    "    bc_dest = list(row['bc_regex_valid'].keys())[0]\n",
    "    regex_valid_list = str(list(row['bc_regex_valid'].values())[0])     # convert list to str to append to df\n",
    "    df_product_bc_regex.loc[index, 'bc_dest'] = bc_dest\n",
    "    df_product_bc_regex.loc[index, 'regex_valid_list'] = regex_valid_list\n",
    "\n",
    "df_product_bc_regex = df_product_bc_regex[['product_name', 'bc_origin', 'bc_dest', 'regex_valid_list']]\n",
    "\n",
    "### KEEP ONLY MOVEMENTS ###\n",
    "# We remove all regex when bc_origin and bc_dest are the same\n",
    "df_product_bc_regex.drop(df_product_bc_regex[df_product_bc_regex['bc_origin']  == df_product_bc_regex['bc_dest']].index, inplace=True)\n",
    "df_product_bc_regex\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f98086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform df_product_bc_regex to bc_regex_final. We select the most common regex_valid among all products per bc.\n",
    "# Build a dictionary bc_regex_valid as {bc_dest1 : [(regex,count), (regex,count)], bc_dest2 : [(regex,count), (regex,count)]}\n",
    "bc_regex_valid = {}\n",
    "for index, row in tqdm(df_product_bc_regex.iterrows()):\n",
    "    bc_dest = row['bc_dest']\n",
    "    regex_list = eval(row['regex_valid_list'])    # use eval to convert str in df to actual list\n",
    "    if bc_dest not in bc_regex_valid :      # populate with the bc_regex_valid with the first bc_dest : regex_list\n",
    "        bc_regex_valid.update({bc_dest : regex_list})\n",
    "    else :\n",
    "        updated_regex_list = bc_regex_valid[bc_dest] + regex_list     # append new regex_list for each bc_dest\n",
    "        bc_regex_valid[bc_dest] = updated_regex_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac6372a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count each iteration of regex per bc_dest to get bc_regex_valid_count = {bc_dest1 : [((regex,count),5), ((regex,count),3)], bc_dest2 : [((regex,count),12), ((regex,count),8)]}\n",
    "bc_regex_valid_count = {}\n",
    "for bc_dest, regex_list in tqdm(bc_regex_valid.items()):\n",
    "    regex_list_count = Counter(regex_list)   # count how many distinct regex per bc\n",
    "    regex_list_count = sorted(regex_list_count.items(), key=lambda x:x[1], reverse=True) # sort in descending order the values\n",
    "    bc_regex_valid_count.update({bc_dest : regex_list_count})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e35e9b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e9d3f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# loop over each regex starting with largest count and check all products catch. Delete the last regex as we don't need anymore\n",
    "bc_regex_final = {k: [] for k in df_product_bc_regex['bc_dest'].unique()}\n",
    "for index, row in tqdm(df_product_bc_regex.iterrows()):\n",
    "    #df_same_bc_dest = df_product_bc_regex.loc[df_product_bc_regex['bc_dest'] == row['bc_dest']]\n",
    "    regex_list = bc_regex_valid_count[row['bc_dest']]\n",
    "\n",
    "    for regex in regex_list :\n",
    "        if re.search(regex[0][0], row['product_name']):\n",
    "            bc_regex_final[row['bc_dest']] += [regex[0][0]]     # append the first regex coming (previously sorted in descending order)\n",
    "            bc_regex_final[row['bc_dest']] = list(set(bc_regex_final[row['bc_dest']]))  # remove if duplicates\n",
    "            break\n",
    "\n",
    "# FORMAT BUSINESS RULE\n",
    "\n",
    "# separate breadcrumb in and out of the scope categ_0\n",
    "category_0_scope = []\n",
    "for breadcrumb in category_breadcrumb : \n",
    "    category_0_scope.append(breadcrumb.split(\"_\")[0])\n",
    "    category_0_scope = list(set(category_0_scope))  # remove if duplicates\n",
    "\n",
    "# populate dict for 3 options : bc with regex for diff categ0 , same categ0 but diff scope , same categ0 same scope\n",
    "bc_regex_diff_categ0 = {}\n",
    "bc_regex_same_categ0_diff_scope = {}\n",
    "bc_regex_same_categ0_same_scope = {}\n",
    "for breadcrumb_destination, regex_list in tqdm(bc_regex_final.items()):\n",
    "    categ0 = breadcrumb_destination.split(\"_\")[0]\n",
    "\n",
    "    if categ0 not in category_0_scope and categ0 not in bc_regex_diff_categ0 :\n",
    "        bc_regex_diff_categ0[categ0] = regex_list\n",
    "\n",
    "    elif categ0 not in category_0_scope and categ0 in bc_regex_diff_categ0 :\n",
    "        bc_regex_diff_categ0[categ0] += regex_list\n",
    "\n",
    "    elif categ0 in category_0_scope and breadcrumb_destination not in category_breadcrumb :\n",
    "        bc_regex_same_categ0_diff_scope[breadcrumb_destination] = regex_list\n",
    "  \n",
    "    elif categ0 in category_0_scope and breadcrumb_destination in category_breadcrumb :\n",
    "        bc_regex_same_categ0_same_scope[breadcrumb_destination] = regex_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7307e95f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b65f5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "### REFORMAT THE REGEX LIST WITH from \"x.*y|x.*z\" to \"x.*(y|z)\"\"###\n",
    "def format_regex_list(regex_list) :\n",
    "    # select only regex with .* for the function\n",
    "    regex_list_with_ast = []\n",
    "    regex_list_no_ast = []\n",
    "    for regex in regex_list :\n",
    "        if '.*' in regex:\n",
    "            regex_list_with_ast.append(regex)\n",
    "        else :\n",
    "            regex_list_no_ast.append(regex)\n",
    "    \n",
    "    first_chars = {}\n",
    "    second_chars = {}\n",
    "    # create 2 dict with first and second chars as keys and empty list as value\n",
    "    for regex in regex_list_with_ast:\n",
    "        first_char = regex.split('.*', 1)[0]\n",
    "        first_chars[first_char]=[]\n",
    "\n",
    "        second_char = regex.split('.*', 1)[1]\n",
    "        second_chars[second_char]=[]\n",
    "\n",
    "\n",
    "    # append to empty lists the second chars\n",
    "    for regex in regex_list_with_ast:\n",
    "        first_char = regex.split('.*', 1)[0]\n",
    "        second_char = regex.split('.*', 1)[1]\n",
    "\n",
    "        first_chars[first_char].append(second_char)\n",
    "        second_chars[second_char].append(first_char)\n",
    "\n",
    "    # append accrodingly to number of second chars taken\n",
    "    formated_regex_list = []\n",
    "    for regex in regex_list_with_ast :\n",
    "        first_char = regex.split('.*', 1)[0]\n",
    "        second_char = regex.split('.*', 1)[1]\n",
    "\n",
    "        if len(first_chars[first_char]) >= 2 :\n",
    "            formated_regex_list.append(first_char + \".*(\" + \"|\".join(first_chars[first_char]) + \")\")\n",
    "        elif len(second_chars[second_char]) >= 2 :\n",
    "            formated_regex_list.append( \"(\" + \"|\".join(second_chars[second_char]) + \").*\" + second_char)  \n",
    "        else :\n",
    "            formated_regex_list.append(regex)\n",
    "\n",
    "    formated_regex_list = list(dict.fromkeys(formated_regex_list))\n",
    "    return(formated_regex_list + regex_list_no_ast)\n",
    "    \n",
    "diff_categ0 = {}\n",
    "for bc, regex_list in bc_regex_diff_categ0.items() :\n",
    "    diff_categ0[bc] = format_regex_list(regex_list)\n",
    "\n",
    "bc_regex_diff_categ0 = diff_categ0\n",
    "\n",
    "\n",
    "same_categ0_diff_scope = {}\n",
    "for bc, regex_list in bc_regex_same_categ0_diff_scope.items() :\n",
    "    same_categ0_diff_scope[bc] = format_regex_list(regex_list)\n",
    "\n",
    "bc_regex_same_categ0_diff_scope = same_categ0_diff_scope\n",
    "\n",
    "\n",
    "same_categ0_same_scope = {}\n",
    "for bc, regex_list in bc_regex_same_categ0_same_scope.items() :\n",
    "    same_categ0_same_scope[bc] = format_regex_list(regex_list)\n",
    "\n",
    "bc_regex_same_categ0_same_scope = same_categ0_same_scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17028afb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d5d83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### INFO ###########\n",
    "print('########### BREADCRUMBS IN OR OUT OUR REGEX MODEL ###########\\n')\n",
    "# dispatch breadcrumbs if in our out our regex model\n",
    "bc_in = {}\n",
    "bc_in_but_no_regex = {}\n",
    "bc_no = []\n",
    "for breadcrumb in df_extract['breadcrumb'].unique() :\n",
    "    if (breadcrumb in list(df_bc_regex['breadcrumb'].unique()) and len(eval(df_bc_regex['regex_list'].loc[df_bc_regex['breadcrumb']==breadcrumb].values[0])) > 0) :\n",
    "        bc_in[breadcrumb] = len(eval(df_bc_regex['regex_list'].loc[df_bc_regex['breadcrumb']==breadcrumb].values[0]))\n",
    "    elif (breadcrumb in list(df_bc_regex['breadcrumb'].unique()) and len(eval(df_bc_regex['regex_list'].loc[df_bc_regex['breadcrumb']==breadcrumb].values[0])) == 0) :\n",
    "        bc_in_but_no_regex[breadcrumb] = len(eval(df_bc_regex['regex_list'].loc[df_bc_regex['breadcrumb']==breadcrumb].values[0]))\n",
    "    else :\n",
    "        bc_no.append(breadcrumb)\n",
    "\n",
    "print('Breadcrumbs IN our regex model')\n",
    "for breadcrumb, regex_count in bc_in.items():\n",
    "    print(f\"-- {breadcrumb} -- is in the regex model with {regex_count} regex combination\")\n",
    "print('\\nBreadcrumbs in our regex model but has no regex :')\n",
    "for breadcrumb, regex_count in bc_in_but_no_regex.items():\n",
    "    print(f\"-- {breadcrumb} -- is in the regex model but with {regex_count} regex combination\")\n",
    "print('\\nBreadcrumbs OUT our regex model :')\n",
    "for breadcrumb in bc_no:\n",
    "    print(f\"-- {breadcrumb} -- is not in the regex model\")\n",
    "\n",
    "\n",
    "print('\\n########### PRODUCTS SUMMARY PER BREADCRUMB ###########')\n",
    "# count number of products per breadcrumb\n",
    "# df_product_catch_sent_unique_bc # df_product_catch_sent_several_bc # df_product_not_catch \n",
    "total_products_sent_one_bc = 0\n",
    "total_products_sent_several_bc = 0\n",
    "total_products_not_catch = 0\n",
    "\n",
    "for breadcrumb in category_breadcrumb:\n",
    "    total_products_sent_one_bc += len(df_product_catch_sent_unique_bc.loc[df_product_catch_sent_unique_bc[\"bc_origin\"]==breadcrumb])\n",
    "    total_products_sent_several_bc += len(df_product_catch_sent_several_bc.loc[df_product_catch_sent_several_bc[\"bc_origin\"]==breadcrumb])\n",
    "    total_products_not_catch += len(df_product_not_catch.loc[df_product_not_catch[\"bc_origin\"]==breadcrumb])\n",
    "    \n",
    "    print(f'\\n{breadcrumb} -->')\n",
    "    print(f'Number of products catch and sent to one breadcrumb - Handled in the BR  : {len(df_product_catch_sent_unique_bc.loc[df_product_catch_sent_unique_bc[\"bc_origin\"]==breadcrumb])}')\n",
    "    print(f'Number of products catch and sent to several breadcrumb - Not handled in the BR : {len(df_product_catch_sent_several_bc.loc[df_product_catch_sent_several_bc[\"bc_origin\"]==breadcrumb])}')\n",
    "    print(f'Number of products not catch - Not handled in the BR : {len(df_product_not_catch.loc[df_product_not_catch[\"bc_origin\"]==breadcrumb])}')\n",
    "\n",
    "print(f'\\nTOTAL movements -->')    \n",
    "print(f'TOTAL of products catch and sent to one breadcrumb - Handled in the BR  : {total_products_sent_one_bc}')\n",
    "print(f'TOTAL of products catch and sent to several breadcrumb - Not handled in the BR : {total_products_sent_several_bc}')\n",
    "print(f'TOTAL of products not catch - Not handled in the BR : {total_products_not_catch}')\n",
    "\n",
    "\n",
    "########### BR FORMAT ###########\n",
    "print('\\n########### BR FORMAT ###########\\n')\n",
    "print('CASE\\n')\n",
    "# loop over different bc_regex and build template for business rule\n",
    "print('-- PROJECTIONS FOR DIFFERENT CATEG0')\n",
    "for categ0, regex_list in bc_regex_diff_categ0.items():\n",
    "    if regex_list :\n",
    "        regex = '|'.join(regex_list)\n",
    "        print(f'''-- {categ0}_uncategorized_uncategorized_uncategorized\n",
    "WHEN REGEXP_CONTAINS(product_name_description, r\"{regex}\")\n",
    "  THEN \"{categ0}_uncategorized_uncategorized_uncategorized\" \\n''')\n",
    "    \n",
    "print('\\n-- PROJECTIONS FOR SAME CATEG0 BUT DIFFERENT SCOPE')\n",
    "for breadcrumb, regex_list in bc_regex_same_categ0_diff_scope.items():\n",
    "    if regex_list :\n",
    "        regex = '|'.join(regex_list)\n",
    "        print(f'''-- {breadcrumb}\n",
    "WHEN REGEXP_CONTAINS(product_name_description, r\"{regex}\")\n",
    "  THEN \"{breadcrumb}\" \\n''')\n",
    "    \n",
    "print('\\n-- PROJECTIONS FOR SAME CATEG0 AND SAME SCOPE')\n",
    "for breadcrumb, regex_list in bc_regex_same_categ0_same_scope.items():\n",
    "    if regex_list :\n",
    "        regex = '|'.join(regex_list)\n",
    "        print(f'''-- {breadcrumb}\n",
    "WHEN REGEXP_CONTAINS(product_name_description, r\"{regex}\")\n",
    "  THEN \"{breadcrumb}\" \\n''')\n",
    "        \n",
    "print('''\\n\\nELSE NULL\n",
    "END''')   \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202a54fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "## INIT THE LOOP \n",
    "#df_volume_checks = pd.DataFrame(columns=['perc_products_sent_one_bc', 'perc_products_sent_several_bc', 'perc_products_not_catch', 'perc_max_prod_catch_from_other_bc'])\n",
    "\n",
    "\n",
    "# CHECK VOLUMES IN LOOP\n",
    "total_products = total_products_sent_one_bc + total_products_sent_several_bc + total_products_not_catch\n",
    "\n",
    "perc_products_sent_one_bc = total_products_sent_one_bc / total_products\n",
    "perc_products_sent_several_bc = total_products_sent_several_bc / total_products\n",
    "perc_products_not_catch = total_products_not_catch / total_products\n",
    "\n",
    "df_newrow = pd.DataFrame({'perc_products_sent_one_bc': [perc_products_sent_one_bc],\n",
    "                    'perc_products_sent_several_bc': [perc_products_sent_several_bc],\n",
    "                         'perc_products_not_catch': [perc_products_not_catch],\n",
    "                         'perc_max_prod_catch_from_other_bc' : [perc_max_prod_catch_from_other_bc]})\n",
    "\n",
    "\n",
    "df_volume_checks=pd.concat([df_volume_checks,df_newrow], axis=0)\n",
    "\n",
    "df_volume_checks.to_csv(df_volume_checks_path)\n",
    "\n",
    "df_volume_checks\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99704cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_extract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ac75e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# df_volume_checks_top100_r1\n",
    "df1 =  pd.read_csv('data/df_volume_checks_top100_r1.csv')\n",
    "plt.rcParams[\"figure.figsize\"] = (10,5)\n",
    "plt.plot(df1['perc_max_prod_catch_from_other_bc']*100, df1['perc_products_sent_one_bc']/len(df_extract)*100, color='green', marker='.', label=\"Products sent to one bc r1 Top 100\")\n",
    "plt.plot(df1['perc_max_prod_catch_from_other_bc']*100, df1['perc_products_sent_several_bc']/len(df_extract)*100, color='green', marker='x', label=\"Products sent to several bc r1 Top 100\")\n",
    "\n",
    "df2 =  pd.read_csv('data/df_volume_checks_top100_r2.csv')\n",
    "plt.plot(df2['perc_max_prod_catch_from_other_bc']*100, df2['perc_products_sent_one_bc']/len(df_extract)*100, color='orange', marker='.', label=\"Products sent to one bc r2 Top 100\")\n",
    "plt.plot(df2['perc_max_prod_catch_from_other_bc']*100, df2['perc_products_sent_several_bc']/len(df_extract)*100, color='orange', marker='x', label=\"Products sent to several bc r2 Top 100\")\n",
    "\n",
    "df3 =  pd.read_csv('data/df_volume_checks_full_loop_r3.csv')\n",
    "plt.plot(df3['perc_max_prod_catch_from_other_bc']*100, df3['perc_products_sent_one_bc']/len(df_extract)*100, color='blue', marker='.', label=\"Products sent to one bc r2 \")\n",
    "plt.plot(df3['perc_max_prod_catch_from_other_bc']*100, df3['perc_products_sent_several_bc']/len(df_extract)*100, color='blue', marker='x', label=\"Products sent to several bc r2 \")\n",
    "\n",
    "\n",
    "\n",
    "plt.title('Regex model precision VS Volume moved by the BR', fontsize=20)\n",
    "plt.xlabel('Percentage of wrong products caught by a regex (%)', fontsize=15)\n",
    "plt.ylabel('Volume of products moved by the BR (%)', fontsize=15)\n",
    "\n",
    "#plt.ylim(2000, 3000)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d163a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e01bce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da801b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ed4443",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66b6ce7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
